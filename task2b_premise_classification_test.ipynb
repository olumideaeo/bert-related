{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "task2b_premise_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "metadata": {
        "id": "ee_x9Yq5hTuO",
        "outputId": "b6195c11-0b49-4578-d326-efa7a84375a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pymagnitude git+https://github.com/huggingface/pytorch-pretrained-BERT.git -q"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jy3gtheyFkHz",
        "outputId": "f42e3d4d-5f28-4d3c-97d9-98913ce42100"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.21.6)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.24.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.12.0+cu113)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.64.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.1.1)\n",
            "Requirement already satisfied: botocore<1.28.0,>=1.27.30 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.27.30)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.6.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.30->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.30->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.30->boto3->pytorch_pretrained_bert) (1.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "vuNg51plR2GM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6fe9796-91d4-4926-9885-38a6ec9bde25"
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_formats = ['svg']\n",
        "\n",
        "import random\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import regex as re\n",
        "#from pymagnitude import Magnitude\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import torch.optim as optim\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "tqdm.pandas()\n",
        "\n",
        "# If the machine you run this on has a GPU available with CUDA installed,\n",
        "# use it. Using a GPU for learning often leads to huge speedups in training.\n",
        "# See https://developer.nvidia.com/cuda-downloads for installing CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/train.tsv', sep='\\t')\n",
        "data_val = pd.read_csv('/content/validation.tsv', sep='\\t')\n",
        "data_test = pd.read_csv('/content/test.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "jo6rDdCsGlYP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert to lowercase\n",
        "data['clean_text']=data['Tweet'].str.lower()\n",
        "#remove URLS\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"http\\S+\", \"\", elem))\n",
        "#remove punctuations\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r\"[^\\w\\s]\", \"\", elem))\n",
        "#remove empty lines\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'/n',\"\",elem))\n",
        "#remove digits\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\d+',\"\",elem))\n",
        "#remove multiple spaces\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+',\" \",elem))\n",
        "#remove single character\n",
        "data['clean_text'] = data['clean_text'].apply(lambda elem:re.sub(r'\\s+[a-zA-Z]\\s+',\" \",elem))"
      ],
      "metadata": {
        "id": "xHiQsSLPGr6z"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "16_l5bChL9sC",
        "outputId": "d356bd32-46ce-4a8e-a497-55133562cabc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 Tweet                Claim  \\\n",
              "0    Ordered a mask that had a cute chain attached ...           face masks   \n",
              "1    Who is ready for some #baseball?  #BaseballisB...  stay at home orders   \n",
              "2    '@Mystere07623203 @va_shiva @Liberty13046 130,...           face masks   \n",
              "3    When they ask me what I did with my life I wil...           face masks   \n",
              "4    Taylor not putting her album in physical store...  stay at home orders   \n",
              "..                                                 ...                  ...   \n",
              "595  @BrianKempGA is one of the few #Governors that...           face masks   \n",
              "596  'I tested positive for Covid. Got it from a fr...           face masks   \n",
              "597  'If you are under retirement age, you have a *...  stay at home orders   \n",
              "598  '@TheLalasventure @doqholliday @realDonaldTrum...           face masks   \n",
              "599  @Caissie Obviously I was simply practicing my ...           face masks   \n",
              "\n",
              "      Stance  Premise  \n",
              "0      FAVOR        0  \n",
              "1       NONE        0  \n",
              "2      FAVOR        1  \n",
              "3      FAVOR        0  \n",
              "4      FAVOR        0  \n",
              "..       ...      ...  \n",
              "595  AGAINST        1  \n",
              "596    FAVOR        1  \n",
              "597  AGAINST        1  \n",
              "598    FAVOR        0  \n",
              "599    FAVOR        0  \n",
              "\n",
              "[600 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d79a1a11-6ad3-418e-8bed-99a95b69706b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Claim</th>\n",
              "      <th>Stance</th>\n",
              "      <th>Premise</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ordered a mask that had a cute chain attached ...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Who is ready for some #baseball?  #BaseballisB...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>NONE</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'@Mystere07623203 @va_shiva @Liberty13046 130,...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>When they ask me what I did with my life I wil...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Taylor not putting her album in physical store...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>@BrianKempGA is one of the few #Governors that...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>'I tested positive for Covid. Got it from a fr...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>'If you are under retirement age, you have a *...</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>AGAINST</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>'@TheLalasventure @doqholliday @realDonaldTrum...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>@Caissie Obviously I was simply practicing my ...</td>\n",
              "      <td>face masks</td>\n",
              "      <td>FAVOR</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d79a1a11-6ad3-418e-8bed-99a95b69706b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d79a1a11-6ad3-418e-8bed-99a95b69706b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d79a1a11-6ad3-418e-8bed-99a95b69706b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test"
      ],
      "metadata": {
        "id": "ONrcvLbI6B56",
        "outputId": "e31cac97-fbca-4ebf-ddbd-4f11203e9f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       id                claim  \\\n",
              "0     1307558525371965442      school closures   \n",
              "1     1247739239879467009  stay at home orders   \n",
              "2     1242046510155653125  stay at home orders   \n",
              "3     1358446499949084675      school closures   \n",
              "4     1249740062775902208  stay at home orders   \n",
              "...                   ...                  ...   \n",
              "9950  1242516037628813314  stay at home orders   \n",
              "9951  1242746919933415424  stay at home orders   \n",
              "9952  1276638598813679617  stay at home orders   \n",
              "9953  1243504288661270528  stay at home orders   \n",
              "9954  1237875841981247488      school closures   \n",
              "\n",
              "                                                   text  \n",
              "0     @narendramodi @rajnathsingh Student ka bhi soa...  \n",
              "1     —échale un vistazo a esto…   … a fair piece on...  \n",
              "2     Why do think skilling women and girls is impor...  \n",
              "3     To reduce the risk of the virus spreading as e...  \n",
              "4     I speak for a great many people when i say WE ...  \n",
              "...                                                 ...  \n",
              "9950  StayAtHomeSaveLives 21daysLockdown StayAtHome ...  \n",
              "9951  If this is true this is heartbreaking StayAtHo...  \n",
              "9952  855 Sunset Cove Dr, Winter Haven, FL 33880 3 B...  \n",
              "9953  StayAtHomeSaveLives StayHomeStaySafe StayHome ...  \n",
              "9954  We’re on track to be like Italy is now. Time t...  \n",
              "\n",
              "[9955 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bebb2d7b-7e6e-412c-9977-308cd6d8aa3c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>claim</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1307558525371965442</td>\n",
              "      <td>school closures</td>\n",
              "      <td>@narendramodi @rajnathsingh Student ka bhi soa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1247739239879467009</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>—échale un vistazo a esto…   … a fair piece on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1242046510155653125</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>Why do think skilling women and girls is impor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1358446499949084675</td>\n",
              "      <td>school closures</td>\n",
              "      <td>To reduce the risk of the virus spreading as e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1249740062775902208</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>I speak for a great many people when i say WE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9950</th>\n",
              "      <td>1242516037628813314</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>StayAtHomeSaveLives 21daysLockdown StayAtHome ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9951</th>\n",
              "      <td>1242746919933415424</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>If this is true this is heartbreaking StayAtHo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9952</th>\n",
              "      <td>1276638598813679617</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>855 Sunset Cove Dr, Winter Haven, FL 33880 3 B...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9953</th>\n",
              "      <td>1243504288661270528</td>\n",
              "      <td>stay at home orders</td>\n",
              "      <td>StayAtHomeSaveLives StayHomeStaySafe StayHome ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9954</th>\n",
              "      <td>1237875841981247488</td>\n",
              "      <td>school closures</td>\n",
              "      <td>We’re on track to be like Italy is now. Time t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9955 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bebb2d7b-7e6e-412c-9977-308cd6d8aa3c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bebb2d7b-7e6e-412c-9977-308cd6d8aa3c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bebb2d7b-7e6e-412c-9977-308cd6d8aa3c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"'\", \"\", text)\n",
        "    text = re.sub(\"(\\\\W)+\", \" \", text)\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "data['train'] = data['clean_text'].apply(clean_text)\n",
        "DATA_PATH = data['train']\n",
        "train_dataset = data['train']\n",
        "valid_dataset = data_val['Tweet']\n",
        "test_dataset = data_test['text']\n",
        "#data_val['val'] = data_val['clean_text'].apply(clean_txt)\n"
      ],
      "metadata": {
        "id": "UrWnV7H-G0IH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4jvvNAoYhSLi"
      },
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, data_path, max_len):\n",
        "        df = data\n",
        "\n",
        "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "        df['tokenized_text'] = df.train.progress_apply(self.tokenizer.tokenize)\n",
        "        \n",
        "        # Shorten to max length (Bert has a limit of 512); subtract two tokens for [CLS] and [SEP]\n",
        "        df.loc[:, 'tokenized_text'] = df.tokenized_text.str[:max_len - 2]\n",
        "        \n",
        "        # Add Bert-specific beginning and end tokens\n",
        "        df.loc[:, 'tokenized_text'] = df.tokenized_text.apply(\n",
        "            lambda tokens: ['[CLS]'] + tokens + ['[SEP]'],\n",
        "        )\n",
        "        \n",
        "        df['indexed_tokens'] = df.tokenized_text.progress_apply(\n",
        "            self.tokenizer.convert_tokens_to_ids,\n",
        "        )\n",
        "        \n",
        "        sequences = df.indexed_tokens.tolist()\n",
        "        max_sequence_length = max(len(x) for x in sequences)\n",
        "        \n",
        "        self.inputs_lst, self.masks, self.segments = [], [], []\n",
        "        for sequence in sequences:\n",
        "            self.inputs_lst.append(sequence + (max_sequence_length - len(sequence)) * [0])\n",
        "            self.masks.append(len(sequence) * [1] + (max_sequence_length - len(sequence)) * [0])\n",
        "            self.segments.append(max_sequence_length * [0])\n",
        "            \n",
        "        self.targets = df.Premise.tolist()\n",
        "        self.texts = df.train.tolist()\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.inputs_lst[i], self.masks[i], self.segments[i], self.targets[i], self.texts[i]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.inputs_lst)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QumAk05hSjIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9953db37-d6c6-4001-a189-68998d759de2"
      },
      "cell_type": "code",
      "source": [
        "# How many tokens long each sequence will be cut to\n",
        "# Shorter sequences will get the padding token <PAD>\n",
        "max_len = 128  #@param {type:\"slider\", min:16, max:512, step:2}\n",
        "\n",
        "dataset = SentimentDataset(DATA_PATH, max_len)\n",
        "dataset_val = SentimentDataset(valid_dataset, max_len)\n",
        "dataset_test = SentimentDataset(test_dataset, max_len)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3556/3556 [00:01<00:00, 1835.89it/s]\n",
            "100%|██████████| 3556/3556 [00:00<00:00, 96846.52it/s]\n",
            "100%|██████████| 3556/3556 [00:01<00:00, 1810.15it/s]\n",
            "100%|██████████| 3556/3556 [00:00<00:00, 101491.21it/s]\n",
            "100%|██████████| 3556/3556 [00:04<00:00, 879.11it/s]\n",
            "100%|██████████| 3556/3556 [00:00<00:00, 54788.23it/s]\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ZIqnhuIuiFly"
      },
      "cell_type": "code",
      "source": [
        "#@title How many examples to load on the GPU at once\n",
        "\n",
        "def collate(batch):\n",
        "    inputs = torch.LongTensor([item[0] for item in batch])\n",
        "    mask = torch.LongTensor([item[1] for item in batch])\n",
        "    segment = torch.LongTensor([item[2] for item in batch])\n",
        "    target = torch.LongTensor([item[3] for item in batch])\n",
        "    text = [item[4] for item in batch]\n",
        "    \n",
        "    inputs, mask, segment, target = map(\n",
        "        lambda x: x.to(device),\n",
        "        (inputs, mask, segment, target),\n",
        "    )\n",
        "\n",
        "    return inputs, mask, segment, target, text\n",
        "\n",
        "batch_size = 32  #@param {type:\"integer\"}\n",
        "\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, collate_fn=collate)\n",
        "valid_loader = DataLoader(dataset_val, batch_size=batch_size, collate_fn=collate)\n",
        "test_loader = DataLoader(dataset_test, batch_size=batch_size, collate_fn=collate)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JzHEyjEauBWy"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model\n",
        "\n",
        "We will train the smaller model `bert-base-uncased` as the larger one has problems fitting into memory. A multi-GPU setup is likely needed for training the larger model. You can find the full list of possible models [here](https://github.com/huggingface/pytorch-pretrained-BERT#loading-google-ai-or-openai-pre-trained-weigths-or-pytorch-dump).\n",
        "\n",
        "- **Learning rate**: How quickly the model learns. If it's too low, the model will learn very slowly. If it's too high, the model won't be able to learn at all. The goal is to have as high as value as we can get away with.\n",
        "\n",
        "Note that learning rate should be lower than what you maybe are used to (eg. 1e-5 instead of 1e-3), as we are only fine-tuning the BERT model instead of training it from scratch. We don't want the model's parameters to drastically change as that will likely result in a decrease in model performance."
      ]
    },
    {
      "metadata": {
        "id": "STlG1-DLib9j"
      },
      "cell_type": "code",
      "source": [
        "def train_epoch(model, optimizer, train_loader):\n",
        "    model.train()\n",
        "    train_loss = total = 0\n",
        "    for inputs, mask, segment, target, text in notebook.tqdm(train_loader,\n",
        "                                                             desc='Training',\n",
        "                                                             leave=False):\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss = model(inputs, segment, mask, target)\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        total += 1\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    return train_loss / total\n",
        "\n",
        "\n",
        "def validate_epoch(model, valid_loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        valid_loss = total = 0\n",
        "        for inputs, mask, segment, target, text in notebook.tqdm(valid_loader,\n",
        "                                                                 desc='Validating',\n",
        "                                                                 leave=False):\n",
        "            loss = model(inputs, segment, mask, target)\n",
        "\n",
        "            valid_loss += loss.item()\n",
        "            total += 1\n",
        "\n",
        "        return valid_loss / total"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title How big of steps the model takes while learning\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model = model.to(device)\n",
        "\n",
        "learning_rate = 0.001  #@param {type:\"number\"}\n",
        "\n",
        "param_optimizer = list(model.classifier.named_parameters()) \n",
        "optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer]}]\n",
        "optimizer = BertAdam(optimizer_grouped_parameters, lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMzZ5k66-oUL",
        "outputId": "7a03db3e-1405-4660-c05b-576fbfb20c0b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:33<00:00, 12182337.97B/s]\n",
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Limit the number of training epochs (training is slow)\n",
        "\n",
        "max_epochs = 3  #@param {type:\"slider\", min:1, max:10}\n",
        "\n",
        "n_epochs = 0\n",
        "train_losses, valid_losses = [], []\n"
      ],
      "metadata": {
        "id": "x5Z8814dQkCq"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2yUBkO8C2BRN"
      },
      "cell_type": "markdown",
      "source": [
        "## Predictions"
      ]
    },
    {
      "metadata": {
        "id": "JHGNXWy-1-VL"
      },
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, mask, segment, target, text in test_loader:\n",
        "        loss = model(inputs, segment, mask, target)\n",
        "        logits = model(inputs, segment, mask)\n",
        "        \n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        predictions = np.argmax(logits, axis=1)\n",
        "        target = target.cpu().numpy()\n",
        "        \n",
        "        y_true.extend(predictions)\n",
        "        y_pred.extend(target)\n",
        "        \n",
        "print(classification_report(y_true, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true"
      ],
      "metadata": {
        "id": "4SFwpdS_Uvvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "znki_Ht7U25V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted = model.predict(X_test)\n",
        "y_predicted = y_predicted.flatten()"
      ],
      "metadata": {
        "id": "a1Vu3dXcU8YG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}